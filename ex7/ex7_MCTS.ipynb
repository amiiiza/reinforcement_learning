{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73680d28-70d7-44bb-9978-7774f5eebf04",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h2 align=\"center\"> <center><b> Reinforcement Learning Assignment 7 - Model Based Reinforcement Learning </b></center></h2>\n",
    "\n",
    "<br>\n",
    "<center><font size=\"3\">This notebook is a part of teaching material for ELEC-E8125</font></center>\n",
    "<center><font size=\"3\">Sep 4, 2023 - Nov 30, 2023</font></center>\n",
    "<center><font size=\"3\">Aalto University</font></center>\n",
    "</div>\n",
    "\n",
    "\n",
    "<a id='TOC'></a>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "# Table of contents\n",
    "* <a href='#1.'> 1. Introduction </a>\n",
    "* <a href='#1.1'> 1.1 Learning Objectives </a>\n",
    "* <a href='#1.2'> 1.2 Code Structure & Files </a>\n",
    "* <a href='#2.'> 2. MCTS </a>\n",
    "* <a href='#3.'> 3. Submitting </a>\n",
    "* <a href='#3.1'> 3.1 Feedback </a>\n",
    "* <a href='#4.'> References</a>\n",
    "    \n",
    "<a href='#Q1'><b>Student Question 1</b> Difficulty of the task (10 points)</a>\\\n",
    "<a href='#T1'><b>Student Task 1.</b> Implementing MCTS (30 points)</a>\\\n",
    "<a href='#Q2'><b>Student Question 2</b> MCTS phases</a>\n",
    "    \n",
    "**Total Points:** 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb74a17-1c90-4f6b-90ea-d3164caf99a1",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='1.'></a>\n",
    "In this section, we will use **Monte Carlo Tree Search (MCTS)** algorithm to solve **DeepSea** environment form [Behaviour Suite for Reinforcement Learning (bsuite)](https://github.com/google-deepmind/bsuite). The environment targets the challenge of exploration and represents a N√óN grid where the agent starts in the top left and has to reach a goal in the bottom right location. At each timestep, the agent moves one row down and can choose one out of two actions. The agent observes the current location and receives a small negative reward of -0.01/N  for moving right and 0 reward for moving left. Additionally, the agent receives a reward of +1 for reaching the goal (treasure) and the episode ends after N timesteps. In this exercise, the number of rows and columns (N) is 10. \n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/deep_sea.png\" width=\"400px\">\n",
    "    <figcaption> Figure 1: Deep-Sea environment </figcaption>\n",
    "</div>\n",
    "\n",
    "## 1.1 Learning Objectives: <a id='1.1'></a>\n",
    "- Understand different phases of MCTS\n",
    "- Implement a simplified version of MCTS\n",
    "\n",
    "## 1.2 Code Structure & Files <a id='1.2'></a>\n",
    "\n",
    "You don‚Äôt have to edit any other file other than ```ex7.ipynb``` to complete this exercise.\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ‚îÄimgs                 # Images used in notebook\n",
    "‚îÇ   ex7_MCTS.ipynb       # Main assignment file containing tasks <---------\n",
    "‚îÇ   env.py               # Wrappers for the environment\n",
    "‚îÇ   simulator.py         # Using the exact environment as the model (simulator)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54855efc-e89b-4386-938b-d6f4bf052f98",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Q1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.</b> Difficulty of the task (10 points)</h3> \n",
    "\n",
    "1.1. What is the probability of reaching the goal state (a function of N) for **DeepSea** environment? <br>\n",
    "1.2. If N is large, DQN (with the $\\epsilon$-greedy policy) usually fail to reach the goal state (in fact, N=10 is already challenging for DQN). In this case, which strategy will DQN converge to? <br>\n",
    "            \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "    üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58072844-b0c4-49f2-bf7b-b4384a4e8959",
   "metadata": {},
   "source": [
    "- The probability of reaching the goal state under a random policy is contingent on the agent consistently opting to 'go right' at each location.\n",
    "\n",
    "- This choice corresponds to selecting one of two options N ‚àí 1 times.\n",
    "\n",
    "- The probability is mathematically expressed as: $$ \\frac{1}{2^{n-1}} $$\n",
    "\n",
    "- In scenarios where N is large, a DQN following an $\\epsilon$-greedy policy initially balances exploration and exploitation.\n",
    "\n",
    "- However, due to the minimal likelihood of reaching the goal through random exploration, the DQN is likely to converge to a policy that consistently chooses to 'go left.'\n",
    "\n",
    "- This choice is locally optimal, but it may prevent the agent from ever reaching the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce37baa-7700-4167-b96b-5e65c990a881",
   "metadata": {},
   "source": [
    "# 2. MCTS <a id='2.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081edfa-3417-44f7-9144-80cc5af076c7",
   "metadata": {},
   "source": [
    "<a id='T1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Task 1.</b> Implement MCTS algorithm (30 points) </h3> \n",
    "\n",
    "Complete ```TODOs``` in the MCTS class below. Specifically, you need to: <br>\n",
    "1. finish the implementation of ```select_action``` method that selects the best action given the MCTS node using UCB1 exploration. <br>\n",
    "2. implement ```simulation``` method where you need to use best action to select the next node and expansion procedure of MCTS when there are no children.\n",
    "3. complete ```backpropagation``` method that updates the attributes of each node in the trajectory. <br>\n",
    "\n",
    "**Ensure that the notebook contains the average return plot.**\n",
    "\n",
    "The reference training plot is as Figure 2 (your plot might look different):\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/mcts_avg_return.png\">\n",
    "    <figcaption> Figure 2: Average episode return for MCTS on DeepSea environment </figcaption>\n",
    "</div>\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e11df358-d684-4d7c-b8ee-d6b3f89258a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bsuite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from env import BsuiteToGymWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "073067c6-6b04-4af9-954d-c1deb58fa1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### MCTS #####\n",
    "class Node(object):\n",
    "    \"\"\" A MCTS Node. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reward: float = 0.\n",
    "        self.visit_count: int = 0\n",
    "        self.done: bool = False\n",
    "        self.total_value: float = 0.  # cumulative value\n",
    "        self.children: dict = {}  # children nodes, index is the action\n",
    "\n",
    "    def expand(self, num_action: int):\n",
    "        \"\"\" Expands this node by adding cild nodes. \"\"\"\n",
    "        for action in range(num_action):\n",
    "            self.children[action] = Node()\n",
    "    \n",
    "    @property\n",
    "    def value(self):  # Q(s, a)\n",
    "        \"\"\"Returns the value of this node.\"\"\"\n",
    "        if self.visit_count:\n",
    "            return self.total_value / self.visit_count\n",
    "        return 0.\n",
    "\n",
    "    @property\n",
    "    def children_visits(self) -> np.ndarray:\n",
    "        \"\"\"Return array of visit counts of visited children.\"\"\"\n",
    "        return np.array([c.visit_count for c in self.children.values()])\n",
    "\n",
    "    @property\n",
    "    def children_values(self) -> np.ndarray:\n",
    "        \"\"\"Return array of values of visited children.\"\"\"\n",
    "        return np.array([c.value for c in self.children.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bccd58bf-c6aa-4cd9-a6a4-5170018f0fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MCTS(object):\n",
    "    def __init__(self, env, discount = 1):\n",
    "        self.env = env\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.discount = discount\n",
    "        self.init_node = Node()\n",
    "        \n",
    "    def select_action(self, node, scale=1):\n",
    "        # TODO: implement selection phase of MCTS algorithm and return the best action.\n",
    "        # Hints:\n",
    "        # 1. If a node has no children, select the random action (use randint from NumPy).\n",
    "        # 2. Otherwise select the next node among node.children as follows:\n",
    "        #     2.1. Compute Q-value and UCB1 (Upper Confidence Bound 1) for node.children using node attributes (see Node class above).\n",
    "        #     2.2. Combine Q-value and UCB1 to balance exploration-exploitation tradeoff by considering scale coefficient.\n",
    "        #     2.3. Select the best action using results from 2.2.\n",
    "        ########## Your code starts here. ##########\n",
    "        # 1. If a node has no children, select the random action (use randint from NumPy).\n",
    "        if len(node.children) == 0:  \n",
    "            return np.random.randint(self.num_actions)\n",
    "        # 2. Otherwise select the next node among node.children as follows:\n",
    "        best_action = None\n",
    "        best_value = float('-inf')\n",
    "        #     2.1. Compute Q-value and UCB1 (Upper Confidence Bound 1) for node.children using node attributes (see Node class above).\n",
    "        for action, child_node in node.children.items():\n",
    "            q_value = child_node.value\n",
    "            exploration_term = np.sqrt(np.log(node.visit_count) / child_node.visit_count)\n",
    "        #     2.2. Combine Q-value and UCB1 to balance exploration-exploitation tradeoff by considering scale coefficient.\n",
    "            ucb_value = q_value + scale * exploration_term\n",
    "        #     2.3. Select the best action using results from 2.2.\n",
    "            if ucb_value > best_value:\n",
    "                best_value = ucb_value\n",
    "                best_action = action\n",
    "        ########## Your code ends here. ##########\n",
    "        return best_action\n",
    "\n",
    "    def simulation(self):\n",
    "        state = self.env.reset()\n",
    "        node = self.init_node\n",
    "        trajectory = [node]\n",
    "\n",
    "        while not node.done:\n",
    "            # TODO: perform simulation phase of MCTS and return the trajectory of MCTS nodes.\n",
    "            # Hints:\n",
    "            # 1. Use self.select_action to select best action for each node.\n",
    "            # 2. Use the best action in self.env.step to get the next state, reward and done.\n",
    "            # 2. If node has no children, use node.expand to perform MCTS expansion phase.\n",
    "            # 3. Use node.children attribute to assign node to the best child of current node.\n",
    "            # 4. Update node.reward and node.done with reward and done values from 2.\n",
    "            # 5. Add node to the trajectory list.\n",
    "            ########## Your code starts here. ##########\n",
    "            # 1. Use self.select_action to select best action for each node.\n",
    "            action = self.select_action(node)\n",
    "            # 2. Use the best action in self.env.step to get the next state, reward and done.\n",
    "            next_state, reward, done, _ = self.env.step(action)\n",
    "            # 2. If node has no children, use node.expand to perform MCTS expansion phase.\n",
    "            if action not in node.children:\n",
    "                node.expand(self.num_actions)\n",
    "                node.children[action].done = done\n",
    "            # 3. Use node.children attribute to assign node to the best child of current node.\n",
    "            node = node.children[action]\n",
    "            # 4. Update node.reward and node.done with reward and done values from 2.\n",
    "            node.reward = reward\n",
    "            node.done = done\n",
    "            # 5. Add node to the trajectory list.\n",
    "            trajectory.append(node)\n",
    "            ########## Your code ends here. ##########\n",
    "        \n",
    "        return trajectory\n",
    "\n",
    "    def backpropagation(self, trajectory):\n",
    "        ep_return = 0\n",
    "        while trajectory:\n",
    "            node = trajectory.pop()\n",
    "            # TODO: implement backpropagation phase of MCTS and return the discounted sum of rewards\n",
    "            # Hints:\n",
    "            # 1. Multiply episode return by self.discount.\n",
    "            # 2. Add node return to episode return. \n",
    "            # 3. Update node total_value with episode return and increase visit_count.\n",
    "            ########## Your code starts here. ##########\n",
    "            # 1. Multiply episode return by self.discount.\n",
    "            ep_return = self.discount * ep_return + node.reward\n",
    "            # 2. Add node return to episode return. \n",
    "            node.total_value = node.total_value + ep_return\n",
    "            # 3. Update node total_value with episode return and increase visit_count.\n",
    "            node.visit_count = node.visit_count + 1\n",
    "            ########## Your code ends here. ##########\n",
    "            \n",
    "        return ep_return\n",
    "\n",
    "    def run(self, num_iteration):\n",
    "        returns = []\n",
    "        for iter in range(num_iteration):\n",
    "            trajectory = self.simulation()\n",
    "            episode_return = self.backpropagation(trajectory)\n",
    "            returns.append(episode_return)\n",
    "            \n",
    "        return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67408669-c97e-446b-8517-390586caae54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[97mLoaded bsuite_id: deep_sea/0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = bsuite.load_from_id('deep_sea/0')\n",
    "env = BsuiteToGymWrapper(env)\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74d91f7c-db90-4d15-817a-1896fed87c21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449/747451268.py:26: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  exploration_term = np.sqrt(np.log(node.visit_count) / child_node.visit_count)\n",
      "/tmp/ipykernel_449/747451268.py:26: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  exploration_term = np.sqrt(np.log(node.visit_count) / child_node.visit_count)\n"
     ]
    }
   ],
   "source": [
    "agent = MCTS(env)\n",
    "returns = agent.run(num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e82a7c24-a9b6-4806-a89c-22af633d821b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# computes average of last 50 episodes\n",
    "avg_returns = [np.mean(returns[-50+i:i]) for i in range(50, num_episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b11ba409-146d-4a2a-83cc-a7877c3a5126",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(avg_returns, linewidth=1.2, color='b')\n",
    "plt.xlabel('Episodes', fontsize=10)\n",
    "plt.ylabel('Return', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8d5d7-d6c4-4b95-98e0-cfde0fbba0c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Q2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 2.</b> MCTS algorithm (5 points)</h3> \n",
    "Describe different phases in MCTS. Explain each one briefly in your own words.\n",
    "<br>\n",
    "<br>\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a8cfe-403a-4551-beb0-f54068353527",
   "metadata": {
    "tags": []
   },
   "source": [
    "Monte Carlo Tree Search (MCTS) is an iterative decision-making method that constructs a search tree, with each node representing a multi-armed bandit. The algorithm consists of four main phases:\n",
    "\n",
    "1. Selection:\n",
    "Starting from the root node, actions are systematically chosen to traverse down the tree until a leaf node is reached. During this process, the algorithm balances exploration and exploitation, similar to techniques used in multi-armed bandit problems, such as the Upper Confidence Bound (UCB1) strategy, to determine the most promising child node.\n",
    "\n",
    "2. Expansion:\n",
    "Once a leaf node is reached, an action is selected, and a new child node is created, becoming the starting point for subsequent simulations.\n",
    "\n",
    "3. Simulation:\n",
    "The algorithm conducts one or more random roll-outs by taking random actions from the newly created child node until the end of the episode or until a predetermined horizon is reached. The value of the state explored in this manner is determined by calculating the mean return across these simulated episodes.\n",
    "\n",
    "4. Backup:\n",
    "Simulated values obtained during the simulation phase are backpropagated from the explored child node all the way up to the root node. This process involves updating the values of intermediate nodes using Monte Carlo estimation, reflecting the cumulative knowledge gained during the search.\n",
    "\n",
    "MCTS effectively combines exploration and exploitation strategies within a tree structure, making it a powerful approach for optimal decision-making in various domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659d502-725a-41f7-a1ad-fac876681fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Submitting <a id='3.'></a>\n",
    "Ensure all tasks and questions (in ```ex7_MCTS.ipynb```) are answered and the relevant plots are recorded in the relevant places. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e45412-1af0-4524-baba-548e88ad4992",
   "metadata": {},
   "source": [
    "## 3.1 Feedback <a id='3.1'></a>\n",
    "\n",
    "In order to help the staff of the course as well as the forthcoming students, it would be great if you could answer to the following questions in your submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364da21-6c7f-4c68-b35a-e308b3f1acff",
   "metadata": {},
   "source": [
    "1) How much time did you spend solving this exercise? (change the ```hrs``` variable below to a floating point number representing the number of hours taken e.g. 5.43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47684b1f-c2de-42d5-9eba-56ebe6ab4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8286772-df2e-4e9d-a783-24acdcbcbbd2",
   "metadata": {},
   "source": [
    "2) Difficulty of each task/question from 1-5 (int or float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a89e6-b33d-4f38-b169-6e871041c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = None # Student Task 1. Implementing MCTS\n",
    "Q1 = None # Question 1.1: Difficulty of the task\n",
    "Q2 = None # Question 2.1: MCTS phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00739461-6f94-43d6-a65a-9a509d061340",
   "metadata": {},
   "source": [
    "3) How well did you understand the content of the task/question from 1-5? (int or float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12a922-a3d4-4297-b1a1-e5819a946949",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = None # Student Task 1. Implementing MCTS\n",
    "Q1 = None # Question 1.1: Difficulty of the task\n",
    "Q2 = None # Question 2.1: MCTS phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f95cba-7e62-4cda-b058-8134b4daa09f",
   "metadata": {},
   "source": [
    "4) General feedback. Consider questions like:\n",
    "\n",
    "    - Did the content of the lecture relate well with the assignment?\n",
    "    - To what extent did you find the material to be potentially useful for your research and studies?\n",
    "    \n",
    "And other feedback you think is worth including. Type in the box below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a57ceb-9879-448b-bdc8-a38af34da4f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Please use the following section to record references.\n",
    "# References <a id='4.'></a>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
